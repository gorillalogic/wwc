{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controversial-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP: Natural Language Processing\n",
    "# --------------------------------\n",
    "\n",
    "#   It's a field of Artificial Intelligence that\n",
    "#   gives the machines the ability to read and understand human language\n",
    "\n",
    "# Facts:\n",
    "#  - Human conversations have a lot of information: Topics, tones, selection of words, phasal verbs, etc.\n",
    "#  - There could be more than a topic, adjetives, nouns in a sentence\n",
    "#  - Data from conversations are examples of unstructued data\n",
    "#  - Unstructured data don't fit in traditional databases (column-row pattern)\n",
    "#  - Human conversations besided being unstructured, they can be in multiple languages\n",
    "\n",
    "# The goal of NLP is to bring techniques in order to create structure out of text data\n",
    "\n",
    "# NLP Use Cases:\n",
    "# - Email classification as Spam vs Legitimate\n",
    "# - Sentiment Analysis of comments\n",
    "# - Analyzing trends from written customer feedbacks\n",
    "# - Understanding text commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP with Spacy\n",
    "# --------------\n",
    "\n",
    "# What is Spacy?\n",
    "# From Real Python page: \n",
    "#   spaCy is a free and open-source library for Natural Language Processing (NLP)\n",
    "#   in Python with a lot of in-built capabilities \n",
    "\n",
    "# Resources:\n",
    "# - https://spacy.io/\n",
    "# - https://realpython.com/natural-language-processing-spacy-python/\n",
    "\n",
    "# Steps for Working with Spacy\n",
    "# - Load the Language Library\n",
    "# - Build a pipeline object\n",
    "# - Using tokens\n",
    "# - Parts-of-Speech tagging\n",
    "# - Undersanding token attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educational-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.en.English'>\n",
      "<spacy.lang.en.English object at 0x7f94250b5850>\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "# Load the Language Library\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "print(type(nlp))\n",
    "print(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "super-sequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're moving to the beautiful L.A.! and i will earn $12.000 dollars monthly as well as Sam\n",
      "<class 'spacy.tokens.doc.Doc'>\n",
      "\n",
      "We 94 PRON\n",
      "'re 99 VERB\n",
      "moving 99 VERB\n",
      "to 84 ADP\n",
      "the 89 DET\n",
      "beautiful 83 ADJ\n",
      "L.A. 95 PROPN\n",
      "! 96 PUNCT\n",
      "and 88 CCONJ\n",
      "i 94 PRON\n",
      "will 99 VERB\n",
      "earn 99 VERB\n",
      "$ 98 SYM\n",
      "12.000 92 NUM\n",
      "dollars 91 NOUN\n",
      "monthly 85 ADV\n",
      "as 85 ADV\n",
      "well 85 ADV\n",
      "as 84 ADP\n",
      "Sam 95 PROPN\n",
      "\n",
      "--------\n",
      "Slicing\n",
      "--------\n",
      "doc[0]: We\n",
      "doc[1]: 're\n",
      "doc[:4]: We're moving to\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "mystr = \"We're moving to the beautiful L.A.! and i will earn $12.000 dollars monthly as well as Sam\"\n",
    "doc = nlp(mystr)\n",
    "print(doc)\n",
    "print(type(doc))\n",
    "print()\n",
    "for token in doc:\n",
    "    print(token.text, token.pos, token.pos_)\n",
    "    \n",
    "# Key things to Analyze\n",
    "# 1. Spacy understands L.A. as an entity\n",
    "# 2. Spacy understands verbs an separate them\n",
    "# 3. Spacy understands punctuations\n",
    "\n",
    "# Other things:\n",
    "# token.text => Give us an individual token\n",
    "# token.pos => Give us a code, and which of the number corresponds to a verb, noun, adjective, etc\n",
    "# token.pos_ => Refers to the main concept of token.pos, but it returns a meaning in a string rather than a code.\n",
    "\n",
    "\n",
    "# Spacy documents can be \"sliced\" & they produce Span Objects\n",
    "print(f\"\\n{'-'*8}\\nSlicing\\n{'-'*8}\")\n",
    "print(f\"doc[0]: {doc[0]}\")\n",
    "print(f\"doc[1]: {doc[1]}\")\n",
    "print(f\"doc[:4]: {doc[:4]}\")\n",
    "sp = doc[1:3]\n",
    "print(type(sp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adjustable-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can do whatever i propose to myself.\n",
      "If i believe it, i will acomplish it.\n",
      "I will neves surrender.\n"
     ]
    }
   ],
   "source": [
    "# Spacy Sentences\n",
    "d1 = nlp(\"I can do whatever i propose to myself. If i believe it, i will acomplish it. I will neves surrender.\")\n",
    "for sentence in d1.sents:\n",
    "    print(sentence)\n",
    "    \n",
    "# Spacy understands that a period plus a space is where the sentence ends.\n",
    "# d1[7].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Pipeline\n",
    "# ------------\n",
    "\n",
    "# What do we mean with pipeline?\n",
    "# \"Doing anything complicated in machine learning usually means building a pipeline.\n",
    "#  The idea is to break up your problem into very small pieces and then use machine\n",
    "#  learning to solve each smaller piece separately. Then by chaining together several\n",
    "#  machine learning models that feed into each other, you can do very complicated things.\"\n",
    "#    Resource: https://medium.com/@suneelpatel.in/nlp-pipeline-building-an-nlp-pipeline-step-by-step-7f0576e11d08 \n",
    "\n",
    "# In order to do NLP, some steps need to be done, the input text enters in a pipeline \n",
    "# (think of a pipeline as the following):\n",
    "\n",
    "# Input Text --> | Operation A | --> | Operation B | --> ... -> | Operation N | ---> Output\n",
    "# To note: Depending on the situation, you can customize your pipeline, re-order the operations (or steps)\n",
    "\n",
    "# Resources\n",
    "# - https://spacy.io/api#architecture-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "editorial-cruise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7f944b301a90>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7f94220147d0>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7f9422014d70>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swedish-daniel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Tokenization\n",
    "# ----------------\n",
    "# - Is the process of breaking up the original text into component pieces (tokens)\n",
    "# - Tokens are pieces of the original text.\n",
    "# - Tokens are the basic building blocks of a doc object\n",
    "# - Tokens help us understand the meaning of a text\n",
    "\n",
    "# Token types\n",
    "# -----------\n",
    "\n",
    "# - Prefix: Character(s) at the beginning ( $(\"Â¿) )\n",
    "# - Suffix: Character(s) at the end ( km ) , . ! )\n",
    "# - Infix: Character(s) in betweeen ( - -- / ... )\n",
    "# - Exception: Special-case rule to split a string into several tokens or\n",
    "#              prevent a token from being split when punctuation rules are\n",
    "#              applied.   ( let's U.S. )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "charitable-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 84\n",
      "more 83\n",
      "information 91\n",
      ", 96\n",
      "you 94\n",
      "can 99\n",
      "contact 99\n",
      "us 94\n",
      "at 84\n",
      "customerservice@mysite.com 100\n",
      "or 88\n",
      "get 99\n",
      "in 84\n",
      "touch 91\n",
      "on 84\n",
      "http://www.mysite.com 100\n"
     ]
    }
   ],
   "source": [
    "str1 = \"For more information, you can contact us at customerservice@mysite.com or get in touch on http://www.mysite.com\"\n",
    "doc_tk = nlp(str1)\n",
    "for tk in doc_tk:\n",
    "    print(tk.text, tk.pos)\n",
    "    \n",
    "# Note that spacy understands that punctuation in email should not be splitted as the token is an email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "normal-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count Spacy Vocab\n",
    "doc_tk.vocab\n",
    "len(doc_tk.vocab) # Number of tokens in the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tight-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Entities: (Juan, Apple, Hong Kong, $6 million)\n",
      "\n",
      "Juan - PERSON - People, including fictional\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Spacy: Token Entities\n",
    "doc2 = nlp(u\"Juan told me, Apple is going to build a Hong Kong factory for $6 million\")\n",
    "print(f\"Doc Entities: {doc2.ents}\")\n",
    "print()\n",
    "\n",
    "for entity in doc2.ents:\n",
    "    print(f\"{entity} - {entity.label_} - {spacy.explain(entity.label_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "applicable-parks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to build a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " factory for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Spacy Displacy: Visualizing Entities\n",
    "doc3 = nlp(u\"Apple is going to build a U.K. factory for $6 million\")\n",
    "spacy.displacy.render(doc3, style='ent', jupyter=True, options={'distance':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
