{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# --------\n",
    "#  We may want to get variations of a word from a text file like 'boat',\n",
    "#  searching for 'boat' might return 'boats', 'boating', 'boater', and so on.\n",
    "#  So, 'boat' would be the stem for ['boats', 'boating', 'boater']\n",
    "\n",
    "#  - Stemming is a method for cataloging related words.\n",
    "#  - Stemming basically chops off the end of words\n",
    "#  - Spacy doesn't include a stemmer, it rely entirely on lemmatization.\n",
    "\n",
    "# Why Stemming? People do it before running analysis in order to try to reduce words to their root idea.\n",
    "#  example: words like am, are, is belong to the verb <Be>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surprising-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: run\t\t-PorterStemmer: run\t-SnowballStemmer: run\n",
      "Word: runner\t\t-PorterStemmer: runner\t-SnowballStemmer: runner\n",
      "Word: ran\t\t-PorterStemmer: ran\t-SnowballStemmer: ran\n",
      "Word: runs\t\t-PorterStemmer: run\t-SnowballStemmer: run\n",
      "Word: easily\t\t-PorterStemmer: easili\t-SnowballStemmer: easili\n",
      "Word: fairly\t\t-PorterStemmer: fairli\t-SnowballStemmer: fair\n",
      "Word: generous\t\t-PorterStemmer: gener\t-SnowballStemmer: generous\n",
      "Word: generation\t\t-PorterStemmer: gener\t-SnowballStemmer: generat\n",
      "Word: generously\t\t-PorterStemmer: gener\t-SnowballStemmer: generous\n",
      "Word: generate\t\t-PorterStemmer: gener\t-SnowballStemmer: generat\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "words = [\n",
    "    'run','runner','ran',\n",
    "    'runs', 'easily', 'fairly',\n",
    "    'generous', 'generation', 'generously',\n",
    "    'generate'\n",
    "]\n",
    "for word in words:\n",
    "    print(f\"Word: {word}\\t\\t-PorterStemmer: {p_stemmer.stem(word)}\\t-SnowballStemmer: {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "professional-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: I went to the lawyer's office to discuss my health insurance\n",
      "Stemmed phrase: i went to the lawyer offic to discuss my health insur\n"
     ]
    }
   ],
   "source": [
    "phrase = \"I went to the lawyer's office to discuss my health insurance\"\n",
    "stemms = [s_stemmer.stem(word) for word in phrase.split()]\n",
    "print(f\"phrase: {phrase}\")\n",
    "print(f\"Stemmed phrase: {' '.join(stemms)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
